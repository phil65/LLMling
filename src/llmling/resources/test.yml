# Version of the configuration schema
# Used for compatibility checking and migrations
version: "1.0"

# Global settings that apply to all components unless overridden
global_settings:
  timeout: 30 # Global timeout in seconds
  max_retries: 3 # Default retry count
  temperature: 0.7 # Default temperature for all LLMs

# Reusable text processors that can be referenced in context definitions
# Each processor either references a Python function or defines a Jinja template
context_processors:
  # Clean and standardize Python code
  python_cleaner:
    type: function
    import_path: code_utils.clean_python_code
    # Function must take str input and return str output
    # Additional parameters can be passed via kwargs in context definitions

  # Remove sensitive information
  sanitize:
    type: function
    import_path: security_utils.remove_sensitive_data
    # Will be called with content as first argument
    # kwargs can include patterns to remove, replacement text, etc.

  # Add metadata header to any content
  add_metadata:
    type: template
    template: |
      # Generated at: {{ now() }}
      # Source: {{ source }}
      # Version: {{ version }}

      {{ content }}
    # Templates always have access to:
    # - content: the text being processed
    # - now(): current datetime
    # - env: environment variables
    # Plus any kwargs passed in the context definition

# LLM provider configurations using litellm format
llm_providers:
  # GPT-4 Turbo configuration
  gpt4-turbo:
    model: openai/gpt-4-1106-preview
    temperature: 0.8
    max_tokens: 4096
    top_p: 0.95
    # Can include any parameter supported by the provider

  # Anthropic Claude configuration
  claude2:
    model: anthropic/claude-2
    temperature: 0.7
    max_tokens: 8192

  # Local model configuration
  local-llama:
    model: ollama/llama2
    temperature: 0.7
    max_tokens: 2048
    # Local models can use the same configuration format

# Groups of providers for different use cases or fallback chains
provider_groups:
  # High-quality responses for code review
  code_review:
    - gpt4-turbo
    - claude2 # Fallback if first model fails

  # Cost-effective group for draft content
  draft_content:
    - local-llama

  # Fallback chain from best to most reliable
  fallback_chain:
    - gpt4-turbo # First choice
    - claude2 # Second choice
    - local-llama # Last resort

# Context definitions - sources of text content
contexts:
  # Loading from a URL
  python_guidelines:
    type: path # Can be URL or file path
    path: "https://example.com/python-guidelines.md"
    description: "Python coding standards and best practices"
    processors: # Chain of processors to apply
      - name: sanitize
        keyword_args: { remove_emails: true }
      - name: add_metadata
        keyword_args:
          source: "company guidelines"
          version: "1.2.3"
  my_utils:
    type: source
    import_path: "my_project.utils"
    description: "Utility module source code"
    recursive: true # Include all submodules
    processors:
      - name: python_cleaner

  single_module:
    type: source
    import_path: "my_project.models.user"
    description: "User model implementation"
    recursive: false # Default, only this module
    include_tests: false # Don't include test files
  system_info:
    type: callable
    import_path: "my_project.utils.system_diagnostics.get_info"
    description: "Current system information"
    keyword_args:
      include_memory: true
      include_disk: true
  # Local file template
  code_review_template:
    type: path
    path: "./templates/code_review.txt"
    description: "Template for code review prompts"
    processors:
      - name: python_cleaner

  # Raw text content
  system_prompt:
    type: text
    content: |
      You are a helpful AI assistant specialized in code review.
      Please analyze the code and provide constructive feedback.
    description: "Default system prompt for code review"

  # Dynamic content from CLI
  git_diff:
    type: cli
    command: "git diff HEAD~1"
    description: "Current git changes"
    shell: true # Execute in shell
    processors:
      - name: python_cleaner
      # Process the git diff output before use

# Groups of related contexts
context_groups:
  # Basic code review contexts
  code_review_basic:
    - system_prompt
    - code_review_template

  # Advanced code review with additional contexts
  code_review_advanced:
    - system_prompt
    - code_review_template
    - python_guidelines
    - git_diff

# Task templates combining providers and contexts
task_templates:
  # Simple code review task
  quick_review:
    provider: local-llama # Single provider
    context: code_review_basic # Context group
    settings: # Task-specific settings
      temperature: 0.7
      max_tokens: 2048

  # Comprehensive code review
  detailed_review:
    provider: code_review # Provider group
    context: code_review_advanced # Context group
    settings:
      temperature: 0.5
      max_tokens: 4096
      # These settings override both global and provider settings

  # Draft generation task
  generate_draft:
    provider: draft_content # Provider group
    context: system_prompt # Single context
    settings:
      temperature: 0.9
      max_tokens: 2048
